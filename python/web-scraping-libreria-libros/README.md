# Web Scraping: ExtracciÃ³n de Datos de LibrerÃ­a Online

[â† Volver al Portafolio Python](../README.md) | [ğŸ““ Ver Notebook](./web-scraping-libreria-libros.ipynb)

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa tÃ©cnicas de web scraping para extraer informaciÃ³n de una librerÃ­a online. Se utilizan herramientas como BeautifulSoup y Selenium para recuperar datos estructurados de pÃ¡ginas web, demostrando diferentes enfoques y niveles de complejidad en la extracciÃ³n de datos.

El sitio web utilizado es [Books to Scrape](http://books.toscrape.com/), una plataforma diseÃ±ada especÃ­ficamente para practicar tÃ©cnicas de scraping.

## ğŸ¯ Objetivos

- Extraer informaciÃ³n estructurada (tÃ­tulos, precios, calificaciones) de pÃ¡ginas web
- Implementar scraping de una sola pÃ¡gina y de mÃºltiples pÃ¡ginas
- Comparar diferentes tÃ©cnicas y herramientas de scraping
- Organizar los datos extraÃ­dos en estructuras de datos manejables (DataFrames)

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.x**
- **BeautifulSoup4** - Parsing de HTML
- **Requests** - Peticiones HTTP
- **Pandas** - ManipulaciÃ³n y estructuraciÃ³n de datos
- **Selenium** - AutomatizaciÃ³n de navegador (opcional)

## ğŸ“ Estructura del Proyecto

```
web-scraping-libreria-libros/
â”œâ”€â”€ web-scraping-libreria-libros.ipynb  # Notebook principal
â”œâ”€â”€ books_to_scrape.png                  # Captura del sitio web
â””â”€â”€ README.md
```

## ğŸš€ InstalaciÃ³n

1. Clonar o descargar el repositorio
2. Instalar las dependencias:

```bash
pip install beautifulsoup4 requests pandas lxml
```

Para usar Selenium (opcional):

```bash
pip install selenium webdriver-manager
```

## ğŸ“– Ejercicios Implementados

### Ejercicio 1: ExtracciÃ³n BÃ¡sica
Recuperar los datos de tÃ­tulo y precio de los 20 libros de la primera pÃ¡gina.

**TecnologÃ­as:** BeautifulSoup, Requests

### Ejercicio 2: ExtracciÃ³n Ampliada
Recuperar tÃ­tulo, precio y calificaciÃ³n (rating) de los 20 libros de la primera pÃ¡gina.

**TecnologÃ­as:** BeautifulSoup, Requests

### Ejercicio 3: Scraping Multi-pÃ¡gina
Recuperar tÃ­tulo, precio y calificaciÃ³n para todos los libros del sitio web (mÃºltiples pÃ¡ginas).

**TecnologÃ­as:** BeautifulSoup, Requests, Selenium (opcional)

## ğŸ’¡ Conceptos Aprendidos

- **Parsing HTML:** Uso de BeautifulSoup para navegar y extraer datos de estructuras HTML
- **Manejo de peticiones HTTP:** Uso de la librerÃ­a Requests para obtener contenido web
- **NavegaciÃ³n entre pÃ¡ginas:** ImplementaciÃ³n de bucles para recorrer mÃºltiples pÃ¡ginas
- **Limpieza de datos:** Procesamiento y transformaciÃ³n de datos extraÃ­dos
- **EstructuraciÃ³n de datos:** OrganizaciÃ³n de datos en DataFrames de Pandas

## ğŸ“ Uso

**ğŸ““ [Abrir Notebook](./web-scraping-libreria-libros.ipynb)**

1. Abrir el notebook `web-scraping-libreria-libros.ipynb` en Jupyter Notebook o JupyterLab
2. Ejecutar las celdas en orden
3. Cada ejercicio estÃ¡ documentado y puede ejecutarse de forma independiente

---

[â† Volver al Portafolio Python](../README.md)

## âš ï¸ Consideraciones Ã‰ticas

Este proyecto utiliza un sitio web diseÃ±ado especÃ­ficamente para practicar scraping. Al realizar web scraping en sitios web reales, es importante:

- Respetar los tÃ©rminos de servicio del sitio web
- Revisar el archivo `robots.txt` del sitio
- Implementar delays entre peticiones para no sobrecargar el servidor
- Usar headers apropiados en las peticiones HTTP
- Considerar el uso de APIs oficiales cuando estÃ©n disponibles

## ğŸ“Š Resultados

El proyecto demuestra la capacidad de extraer y estructurar datos de pÃ¡ginas web, obteniendo informaciÃ³n de cientos de libros organizada en un DataFrame de Pandas para su posterior anÃ¡lisis.

## ğŸ”— Referencias

- [Books to Scrape](http://books.toscrape.com/) - Sitio web utilizado para el proyecto
- [BeautifulSoup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [Requests Documentation](https://requests.readthedocs.io/)


