# Reducci√≥n de Dimensionalidad con PCA para An√°lisis de Veh√≠culos

[‚Üê Volver al √≠ndice](../README.md) | [üìì Ver Notebook](./pca_vehicle_analysis.ipynb)

## Descripci√≥n

Este proyecto aplica la t√©cnica de An√°lisis de Componentes Principales (PCA) para reducir la dimensionalidad de un dataset con caracter√≠sticas de distintos modelos de veh√≠culos. El objetivo es visualizar y analizar las diferencias entre todoterrenos (Cars) y turismos (Passenger) en un espacio de dimensiones reducidas, conservando la mayor parte de la informaci√≥n original.

## Objetivo

El objetivo principal es:
- Reducir la dimensionalidad de un dataset con m√∫ltiples caracter√≠sticas de veh√≠culos
- Identificar las componentes principales que capturan la mayor variabilidad
- Evaluar si los diferentes tipos de veh√≠culos (todoterrenos y turismos) quedan identificados en el espacio reducido
- Interpretar el significado de las componentes principales en t√©rminos de las variables originales

## Dataset

- **Archivo**: `Car_sales.csv`
- **Descripci√≥n**: Dataset con caracter√≠sticas de 157 modelos de veh√≠culos
- **Variables principales** (15 en total):
  - `Manufacturer`: Fabricante del veh√≠culo
  - `Model`: Modelo del veh√≠culo
  - `Sales_in_thousands`: Ventas en miles
  - `4_year_resale_value`: Valor de reventa a 4 a√±os
  - `Vehicle_type`: Tipo de veh√≠culo (Car/Passenger)
  - `Price_in_thousands`: Precio en miles
  - `Engine_size`: Tama√±o del motor
  - `Horsepower`: Potencia
  - `Wheelbase`: Distancia entre ejes
  - `Width`: Ancho
  - `Length`: Longitud
  - `Curb_weight`: Peso
  - `Fuel_capacity`: Capacidad de combustible
  - `Fuel_efficiency`: Eficiencia de combustible
  - `Latest_Launch`: √öltimo lanzamiento

## Herramientas y T√©cnicas Empleadas

### Librer√≠as de Python
- **pandas**: Manipulaci√≥n y an√°lisis de datos
- **numpy**: Operaciones num√©ricas
- **matplotlib**: Visualizaci√≥n de datos (2D y 3D)
- **seaborn**: Visualizaciones estad√≠sticas avanzadas
- **scikit-learn**: PCA, StandardScaler

### T√©cnicas Implementadas

1. **An√°lisis de Componentes Principales (PCA)**
   - Reducci√≥n de dimensionalidad de 10 a 3 variables
   - M√©todo del codo para determinar n√∫mero √≥ptimo de componentes
   - An√°lisis de varianza explicada
   - Interpretaci√≥n de componentes mediante loadings y correlaciones

2. **Preprocesamiento de Datos**
   - Limpieza de nombres de variables
   - Conversi√≥n de tipos de datos
   - Tratamiento de valores faltantes (imputaci√≥n con mediana/media)
   - Estandarizaci√≥n de variables (StandardScaler)

3. **An√°lisis Exploratorio**
   - An√°lisis de distribuciones
   - Matriz de correlaciones
   - Visualizaci√≥n de datos en 2D y 3D
   - Validaci√≥n con casos de prueba

## Temas Cubiertos

- **PCA**: Fundamentos te√≥ricos y aplicaci√≥n pr√°ctica
- **Reducci√≥n de dimensionalidad**: De 10 variables a 3 componentes principales
- **Estandarizaci√≥n de datos**: Importancia y aplicaci√≥n
- **An√°lisis de varianza explicada**: M√©todo del codo y selecci√≥n de componentes
- **Interpretaci√≥n de componentes**: Relaci√≥n con variables originales
- **Visualizaci√≥n multidimensional**: Representaci√≥n en espacios reducidos

## Ejecuci√≥n

### Requisitos Previos

1. Python 3.7 o superior
2. Jupyter Notebook o JupyterLab
3. Instalaci√≥n de dependencias (ver secci√≥n Dependencias)

### Pasos para Ejecutar

1. Clonar o descargar el repositorio
2. Navegar al directorio del proyecto:
   ```bash
   cd pca_vehicle_analysis
   ```

3. Instalar las dependencias:
   ```bash
   pip install -r requirements.txt
   ```

4. Abrir el notebook:
   ```bash
   jupyter notebook pca_vehicle_analysis.ipynb
   ```

5. Ejecutar las celdas en orden secuencial

## Dependencias

Las siguientes librer√≠as son necesarias para ejecutar el proyecto:

```
pandas>=1.3.0
numpy>=1.21.0
matplotlib>=3.4.0
seaborn>=0.11.0
scikit-learn>=1.0.0
jupyter>=1.0.0
```

### Instalaci√≥n de Dependencias

```bash
pip install pandas numpy matplotlib seaborn scikit-learn jupyter
```

## C√≥mo Usar

### Preprocesamiento

1. Cargar el dataset `Car_sales.csv`
2. Limpiar nombres de variables (eliminar espacios)
3. Convertir tipos de datos apropiados
4. Tratar valores faltantes (imputaci√≥n)
5. Estandarizar variables num√©ricas

### Aplicaci√≥n de PCA

1. Seleccionar variables num√©ricas para PCA (10 variables)
2. Aplicar m√©todo del codo para determinar n√∫mero √≥ptimo de componentes
3. Aplicar PCA con 3 componentes (86.61% de varianza explicada)
4. Visualizar resultados en 2D y 3D
5. Interpretar componentes mediante correlaciones

### Validaci√≥n

1. Seleccionar casos de prueba (uno de cada tipo de veh√≠culo)
2. Transformar casos de prueba al espacio PCA
3. Evaluar capacidad de clasificaci√≥n

## Resultados Obtenidos

### Reducci√≥n de Dimensionalidad

- **Variables iniciales**: 10 variables num√©ricas
- **Componentes seleccionadas**: 3 componentes principales
- **Varianza explicada**:
  - PC1: 59.77% (tama√±o y potencia del veh√≠culo)
  - PC2: 20.18% (aspectos econ√≥micos y dimensiones)
  - PC3: 6.66% (eficiencia y caracter√≠sticas adicionales)
- **Varianza total conservada**: 86.61%

### Interpretaci√≥n de Componentes

**Primera Componente (PC1) - 59.77%:**
- Representa principalmente el tama√±o y potencia del veh√≠culo
- Variables m√°s importantes: Curb_weight (0.911), Engine_size (0.894), Fuel_capacity (0.853)
- Valores positivos: veh√≠culos grandes y potentes (t√≠pico de Cars)
- Valores negativos: veh√≠culos peque√±os y menos potentes (t√≠pico de Passenger)

**Segunda Componente (PC2) - 20.18%:**
- Representa aspectos econ√≥micos y algunas dimensiones
- Variables m√°s importantes: 4_year_resale_value (0.761), Price_in_thousands (0.665)
- Menos √∫til para distinguir entre tipos de veh√≠culos

**Tercera Componente (PC3) - 6.66%:**
- Relacionada con eficiencia y caracter√≠sticas adicionales
- Muestra mejor separaci√≥n entre Cars (valores negativos) y Passenger (valores positivos)

### Separaci√≥n de Grupos

- **PC1 vs PC2**: Separaci√≥n moderada con solapamiento considerable
- **PC1 vs PC3**: Mejor separaci√≥n, menor solapamiento
- **PC2 vs PC3**: Separaci√≥n m√°s clara entre grupos
- **Visualizaci√≥n 3D**: La combinaci√≥n de las tres componentes ayuda a distinguir mejor los grupos

## Insights Clave

1. **Reducci√≥n efectiva**: Se logr√≥ reducir de 10 dimensiones a 3, conservando m√°s del 85% de la varianza.

2. **PC1 como diferenciador principal**: La primera componente es la m√°s efectiva para distinguir entre tipos de veh√≠culos, representando principalmente tama√±o y potencia.

3. **Solapamiento entre categor√≠as**: Existe solapamiento entre Cars y Passenger, indicando caracter√≠sticas compartidas. Esto es esperado ya que algunos veh√≠culos pueden tener caracter√≠sticas intermedias.

4. **Casos extremos**: Los casos extremos (como Cadillac Escalade) son m√°s f√°ciles de clasificar que los casos intermedios (como Acura Integra).

5. **Correlaciones identificadas**: Se identificaron altas correlaciones entre variables relacionadas (tama√±o, potencia, eficiencia), lo que justifica la efectividad de PCA.

6. **Aplicaciones pr√°cticas**: PCA es √∫til para visualizaci√≥n, reducci√≥n de ruido, y preprocesamiento para algoritmos de machine learning.

## Estructura de Carpeta

```
pca_vehicle_analysis/
‚îÇ
‚îú‚îÄ‚îÄ pca_vehicle_analysis.ipynb  # Notebook principal
‚îú‚îÄ‚îÄ Car_sales.csv                # Dataset de veh√≠culos
‚îú‚îÄ‚îÄ coches.jpeg                  # Imagen ilustrativa
‚îú‚îÄ‚îÄ README.md                    # Este archivo
‚îî‚îÄ‚îÄ requirements.txt             # Dependencias
```

## Enlaces

- **üìì Notebook Principal**: [pca_vehicle_analysis.ipynb](./pca_vehicle_analysis.ipynb)
- **Dataset**: [Car_sales.csv](./Car_sales.csv)
- **Documentaci√≥n scikit-learn PCA**: [https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)

## Licencia

Este proyecto es de c√≥digo abierto y est√° disponible para uso educativo y de investigaci√≥n.

---

**Nota**: Este proyecto demuestra la aplicaci√≥n pr√°ctica de t√©cnicas de reducci√≥n de dimensionalidad para an√°lisis exploratorio y visualizaci√≥n de datos de alta dimensionalidad.

