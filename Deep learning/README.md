# üß† Deep Learning

Este portafolio contiene proyectos de Deep Learning que demuestran el uso de redes neuronales profundas para resolver problemas complejos de clasificaci√≥n, procesamiento de secuencias y visi√≥n por computadora.

## üìö Proyectos Incluidos

### 1. [Clasificaci√≥n de Secuencias con LSTM](./clasificacion_secuencias_lstm/)
**Notebook:** [`clasificacion_secuencias_lstm.ipynb`](./clasificacion_secuencias_lstm/clasificacion_secuencias_lstm.ipynb)

**Objetivo:** Implementar un modelo LSTM para clasificaci√≥n de sentimientos en rese√±as de pel√≠culas del dataset IMDB.

**Descripci√≥n:** Este proyecto utiliza redes LSTM (Long Short-Term Memory) para analizar secuencias de texto y clasificar rese√±as de pel√≠culas como positivas o negativas. Incluye un an√°lisis exhaustivo de 7+ iteraciones de optimizaci√≥n, comparando diferentes arquitecturas (LSTM pura, CNN+LSTM, Bidirectional LSTM, Stacked LSTM) y t√©cnicas de regularizaci√≥n.

**Resultados clave:**
- **Mejor resultado:** Bidirectional LSTM con 87.66% de test accuracy
- Callbacks (EarlyStopping + ReduceLROnPlateau) mejoraron resultados de ~83% a ~87%
- Experimentaci√≥n con embeddings pre-entrenados (GloVe) y fine-tuning

**Tecnolog√≠as utilizadas:**
- TensorFlow/Keras
- LSTM (Long Short-Term Memory)
- Embeddings (GloVe)
- Procesamiento de secuencias

**Temas cubiertos:**
- Procesamiento de texto
- Redes neuronales recurrentes (RNN)
- LSTM para clasificaci√≥n de secuencias
- Embeddings pre-entrenados
- An√°lisis de sentimientos

---

### 2. [Clasificaci√≥n de Im√°genes con CNN](./clasificacion_imagenes_cnn/)
**Notebooks:** 
- [`01_cnn_template.ipynb`](./clasificacion_imagenes_cnn/01_cnn_template.ipynb) - CNN desde cero
- [`02_cnn_template.ipynb`](./clasificacion_imagenes_cnn/02_cnn_template.ipynb) - Reducci√≥n de sobreentrenamiento
- [`03_cnn_template.ipynb`](./clasificacion_imagenes_cnn/03_cnn_template.ipynb) - Transfer learning
- [`04_cnn_template_.ipynb`](./clasificacion_imagenes_cnn/04_cnn_template_.ipynb) - Optimizaci√≥n avanzada

**Objetivo:** Construir y optimizar redes neuronales convolucionales (CNN) para clasificaci√≥n de im√°genes (perros vs gatos).

**Descripci√≥n:** Serie de proyectos que progresan desde la construcci√≥n de una CNN b√°sica hasta t√©cnicas avanzadas de optimizaci√≥n. Incluye experimentaci√≥n exhaustiva con data augmentation, an√°lisis sistem√°tico de valores de dropout (0.1 a 0.9), transfer learning con Inception V3, y aplicaci√≥n a diferentes dominios (perros/gatos ‚Üí flores).

**Resultados clave:**
- **Mejor dropout:** 0.5 (val accuracy: 78.40%)
- **Inception V3:** Mejora de ~70% a ~74-76% en clasificaci√≥n de flores
- Data augmentation reduce significativamente el sobreajuste
- Transfer learning funciona con diferentes tama√±os de imagen (299x299 ‚Üí 150x150)

**Tecnolog√≠as utilizadas:**
- TensorFlow/Keras
- CNN (Convolutional Neural Networks)
- Transfer Learning
- Data Augmentation
- Dropout

**Temas cubiertos:**
- Arquitecturas CNN
- Clasificaci√≥n de im√°genes
- Data augmentation
- Regularizaci√≥n (dropout)
- Transfer learning
- Fine-tuning

---

### 3. [Detecci√≥n de Objetos con YOLO](./deteccion_objetos_yolo/)
**Notebook:** [`yolo.ipynb`](./deteccion_objetos_yolo/yolo.ipynb)

**Objetivo:** Implementar detecci√≥n de objetos en tiempo real utilizando YOLOv5.

**Descripci√≥n:** Este proyecto utiliza YOLOv5 (You Only Look Once) para detectar y localizar objetos en im√°genes. YOLO divide la imagen en cuadr√≠culas y predice d√≥nde est√°n los objetos y qu√© son en una sola pasada, siendo mucho m√°s r√°pido que otros m√©todos. Se entrena durante 50 √©pocas en COCO128 y se eval√∫a en diferentes tipos de im√°genes.

**Resultados clave:**
- Entrenamiento exitoso durante 50 √©pocas en dataset COCO128
- Detecci√≥n precisa de m√∫ltiples objetos en una sola pasada
- Visualizaci√≥n de detecciones en validaci√≥n y en im√°genes externas (Picsum)
- Aplicaci√≥n pr√°ctica previa: Detecci√≥n de personajes vs objetos en videos de Fortnite para un recomendador de emotes

**Tecnolog√≠as utilizadas:**
- PyTorch
- YOLOv5
- OpenCV
- Detecci√≥n de objetos

**Temas cubiertos:**
- Detecci√≥n de objetos
- YOLO (You Only Look Once)
- Entrenamiento de modelos de visi√≥n
- Evaluaci√≥n de detecci√≥n

---

### 4. [Redes Neuronales DNN](./redes_neuronales_dnn/)
**Notebooks:**
- [`S5_DL_practice1_XOR.ipynb`](./redes_neuronales_dnn/notebooks/S5_DL_practice1_XOR.ipynb) - Problema XOR
- [`S5_DL_practice1_FasMNIST.ipynb`](./redes_neuronales_dnn/notebooks/S5_DL_practice1_FasMNIST.ipynb) - Fashion MNIST

**Objetivo:** Implementar y optimizar redes neuronales densas (DNN) para problemas de clasificaci√≥n.

**Descripci√≥n:** Dos proyectos que demuestran el uso de redes neuronales multicapa: uno resuelve el problema cl√°sico XOR (no linealmente separable) y otro clasifica im√°genes de ropa del dataset Fashion MNIST. El proyecto Fashion MNIST incluye experimentaci√≥n exhaustiva con normalizaci√≥n (3 tipos), optimizaci√≥n de learning rate, y callbacks avanzados.

**Resultados clave:**
- **Fashion MNIST:** ReduceLROnPlateau mejora de 88.25% a 90.14% de precisi√≥n
- **Mejor normalizaci√≥n:** Estandarizaci√≥n N(0,1) con 88.71% de precisi√≥n
- **Learning rate √≥ptimo:** 0.001 (balance entre velocidad y precisi√≥n)
- **XOR:** Resoluci√≥n exitosa con arquitectura 2-2-1, demostrando la necesidad de capas ocultas

**Tecnolog√≠as utilizadas:**
- TensorFlow/Keras
- DNN (Deep Neural Networks)
- Optimizaci√≥n de hiperpar√°metros
- Procesamiento de im√°genes

**Temas cubiertos:**
- Redes neuronales densas
- Problemas no linealmente separables
- Clasificaci√≥n multiclase
- Optimizaci√≥n de modelos
- Preprocesamiento de datos

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

- **Frameworks:** TensorFlow, Keras, PyTorch
- **Redes Neuronales:** LSTM (Bidirectional, Stacked), CNN, DNN, YOLO
- **Modelos Pre-entrenados:** Inception V3, VGG, ResNet, GloVe
- **Procesamiento:** Texto, Im√°genes, Secuencias
- **T√©cnicas:** Transfer Learning, Data Augmentation, Regularizaci√≥n (Dropout, L2, SpatialDropout1D)
- **Callbacks:** ReduceLROnPlateau, EarlyStopping
- **Optimizaci√≥n:** SGD, Adam, AdamW

## üìñ Temas Cubiertos

### Fundamentos
- Redes neuronales profundas (DNN)
- Problemas no linealmente separables (XOR)
- Normalizaci√≥n de datos (escalado, centrado, estandarizaci√≥n)
- Optimizaci√≥n de learning rate
- Callbacks avanzados (ReduceLROnPlateau, EarlyStopping)

### Procesamiento de Secuencias
- LSTM (Long Short-Term Memory)
- Bidirectional LSTM
- Stacked LSTM
- CNN + LSTM para secuencias
- Embeddings pre-entrenados (GloVe)
- An√°lisis de sentimientos en texto

### Visi√≥n por Computadora
- CNN (Convolutional Neural Networks)
- Data augmentation exhaustivo
- Regularizaci√≥n (Dropout, SpatialDropout1D)
- Transfer learning (Inception V3, VGG, ResNet)
- Fine-tuning de modelos pre-entrenados
- Detecci√≥n de objetos (YOLO)

### Optimizaci√≥n y Regularizaci√≥n
- Experimentaci√≥n sistem√°tica con hiperpar√°metros
- An√°lisis de curvas de aprendizaje
- T√©cnicas de regularizaci√≥n avanzadas
- Comparaci√≥n de arquitecturas

## üöÄ C√≥mo Navegar este Portafolio

1. Cada proyecto tiene su propia carpeta con el notebook correspondiente
2. Los notebooks est√°n listos para ejecutarse (requieren las dependencias instaladas)
3. Cada proyecto incluye explicaciones y an√°lisis de resultados
4. Los modelos est√°n entrenados y listos para evaluaci√≥n

## üìù Notas

- Algunos proyectos requieren GPU para entrenamiento eficiente
- Los datasets se descargan autom√°ticamente o est√°n incluidos
- Los modelos entrenados pueden estar guardados en formato `.keras` o `.h5`

## üìÑ Licencia

Este portafolio es de uso personal y educativo.

