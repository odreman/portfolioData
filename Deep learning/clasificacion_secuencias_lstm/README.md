# Clasificaci√≥n de Secuencias con LSTM

## üìã Descripci√≥n

Este proyecto implementa un modelo de clasificaci√≥n de sentimientos utilizando redes LSTM (Long Short-Term Memory) para analizar rese√±as de pel√≠culas del dataset IMDB. El modelo es capaz de clasificar rese√±as como positivas o negativas bas√°ndose en el contenido del texto.

El proyecto incluye un an√°lisis exhaustivo de diferentes arquitecturas y t√©cnicas de optimizaci√≥n, desde una LSTM b√°sica hasta combinaciones avanzadas con CNN, embeddings pre-entrenados (GloVe), y t√©cnicas de regularizaci√≥n.

## üéØ Objetivo

Desarrollar y optimizar un modelo LSTM que pueda procesar secuencias de texto y realizar clasificaci√≥n binaria de sentimientos con alta precisi√≥n. El proyecto explora m√∫ltiples iteraciones de optimizaci√≥n para encontrar la mejor configuraci√≥n del modelo.

## üîß Tecnolog√≠as Utilizadas

- **TensorFlow/Keras:** Framework principal para deep learning
- **LSTM:** Redes neuronales recurrentes para procesamiento de secuencias
- **GloVe:** Embeddings pre-entrenados para representaci√≥n de palabras
- **NumPy:** Procesamiento num√©rico
- **Matplotlib:** Visualizaci√≥n de resultados

## üìä Dataset

- **IMDB Movie Reviews:** Dataset de 50,000 rese√±as de pel√≠culas etiquetadas como positivas o negativas
- Preprocesamiento: Tokenizaci√≥n, padding de secuencias, limitaci√≥n de vocabulario

## üèóÔ∏è Arquitecturas Implementadas

El proyecto explora m√∫ltiples arquitecturas y configuraciones:

### Arquitectura Base
1. **Embedding Layer:** Convierte palabras en vectores densos
2. **LSTM Layer:** Procesa secuencias de texto
3. **Dense Layer:** Clasificaci√≥n binaria (sigmoid)

### Variaciones Implementadas

1. **LSTM con Dropout:** Regularizaci√≥n para reducir sobreajuste
2. **CNN + LSTM + DNN:** Combinaci√≥n de capas convolucionales para extracci√≥n de caracter√≠sticas locales, seguida de LSTM para procesamiento secuencial
3. **Bidirectional LSTM:** Procesamiento bidireccional para capturar contexto en ambas direcciones
4. **Stacked LSTM:** M√∫ltiples capas LSTM apiladas
5. **GloVe + Fine-tuning:** Embeddings pre-entrenados con ajuste fino

## üìà Caracter√≠sticas Principales

- **An√°lisis de curvas de aprendizaje:** Identificaci√≥n de sobreajuste y problemas de generalizaci√≥n
- **M√∫ltiples iteraciones de optimizaci√≥n:** 7+ variaciones del modelo probadas sistem√°ticamente
- **T√©cnicas de regularizaci√≥n:** Dropout, SpatialDropout1D, L2 regularization, recurrent dropout
- **Callbacks avanzados:** EarlyStopping y ReduceLROnPlateau para optimizaci√≥n autom√°tica
- **Comparaci√≥n de arquitecturas:** LSTM pura, CNN+LSTM, Bidirectional LSTM, Stacked LSTM
- **Embeddings pre-entrenados:** Experimentaci√≥n con GloVe (100 dimensiones) y fine-tuning
- **Evaluaci√≥n rigurosa:** An√°lisis detallado de resultados en conjunto de test

## üéØ Resultados Principales

### Mejores Resultados Obtenidos

| Iteraci√≥n | Configuraci√≥n | Test Accuracy |
|-----------|---------------|---------------|
| **Iteraci√≥n 5** | **Bidirectional LSTM (64 unidades)** | **0.8766** ‚≠ê |
| Iteraci√≥n 1 | Full data + EarlyStopping/ReduceLROnPlateau | 0.8734 |
| Iteraci√≥n 2 | + Dropout final (0.5) | 0.8736 |
| Iteraci√≥n 6 | SpatialDropout1D (0.3) | 0.8711 |
| Iteraci√≥n 7 | Stacked LSTM (2√ó64 unidades) | 0.8669 |
| GloVe + Fine-tuning | Embeddings pre-entrenados | 0.8661 |
| Iteraci√≥n 3 | Adam + recurrent dropout (0.3) | 0.8628 |
| Iteraci√≥n 4 | L2 reg + dropout ajustado | 0.8642 |

### Hallazgos Clave

1. **Bidirectional LSTM fue la mejor arquitectura:** Captura contexto en ambas direcciones sin a√±adir excesivo ruido o par√°metros que requieran m√°s datos.

2. **Callbacks fueron la mejora m√°s efectiva:** EarlyStopping y ReduceLROnPlateau mejoraron los resultados de ~0.83 a ~0.87 sin modificar la arquitectura.

3. **Dropout final tuvo impacto limitado:** La red ya estaba suficientemente regularizada con los callbacks.

4. **Regularizaciones internas degradaron el rendimiento:** Recurrent dropout y L2 regularization introdujeron demasiado "ruido" en la memoria secuencial, penalizando la capacidad de retener contexto.

5. **Arquitecturas m√°s complejas no mejoraron:** Stacked LSTM y combinaciones complejas habr√≠an necesitado m√°s datos o embeddings mejor adaptados para no sobreajustar.

6. **GloVe no super√≥ el modelo puro:** Aunque proporcion√≥ curvas m√°s estables, el embedding general (Wikipedia+Gigaword) no se adapt√≥ completamente al dominio espec√≠fico de rese√±as de cine.

### An√°lisis de Sobreajuste

- **Problema inicial:** El modelo base mostraba memorizaci√≥n r√°pida (train accuracy ~99-100%) pero generalizaci√≥n pobre (val accuracy ~80-82%).
  - La p√©rdida de validaci√≥n rebotaba (picos en √©pocas 3, 6, 8, 10...) en lugar de descender de forma sostenida, se√±al de que el modelo "aprend√≠a ruido" del conjunto de entrenamiento.
- **Soluci√≥n:** Implementaci√≥n de t√©cnicas de regularizaci√≥n y callbacks que redujeron el gap entre entrenamiento y validaci√≥n.
- **Resultado final:** Modelo con mejor balance entre capacidad de aprendizaje y generalizaci√≥n.

### Detalles de Iteraciones Espec√≠ficas

**Iteraci√≥n 1 (Full data + Callbacks):**
- Split 80/20 para entrenamiento/validaci√≥n
- EarlyStopping y ReduceLROnPlateau implementados
- Mejora m√°s efectiva: de ~0.83 a ~0.87 sin modificar arquitectura

**Iteraci√≥n 2 (+ Dropout final):**
- Dropout de 0.5 antes de la capa de salida
- Impacto marginal porque la red ya estaba suficientemente regularizada

**Iteraci√≥n 5 (Bidirectional LSTM):**
- 64 unidades en cada direcci√≥n
- Mejor resultado individual: 0.8766 test accuracy
- Captura contexto en ambas direcciones sin a√±adir excesivo ruido

**Iteraci√≥n 6 (SpatialDropout1D):**
- SpatialDropout1D de 0.3 tras el Embedding
- Regulariz√≥ demasiado la entrada, dificultando la retenci√≥n de secuencias clave

**Iteraci√≥n 7 (Stacked LSTM):**
- Dos capas LSTM de 64 unidades cada una
- Duplic√≥ par√°metros recurrentes, insuficiente con ~20,000 ejemplos para afinar ambas capas sin sobreajustar

**GloVe + Fine-tuning:**
- Embeddings GloVe 100d (Wikipedia + Gigaword)
- Curvas muy estables con gap m√≠nimo entre train/val
- No super√≥ el 87% porque el embedding general no se adapt√≥ completamente al dominio de rese√±as de cine

## üöÄ Ejecuci√≥n

```bash
# Instalar dependencias
pip install tensorflow numpy matplotlib

# Ejecutar notebook
jupyter notebook clasificacion_secuencias_lstm.ipynb
```

## üî¨ Metodolog√≠a de Experimentaci√≥n

El proyecto sigue una metodolog√≠a sistem√°tica de experimentaci√≥n:

1. **An√°lisis inicial:** Identificaci√≥n de problemas de sobreajuste mediante curvas de aprendizaje
2. **Iteraci√≥n incremental:** Cada variaci√≥n se basa en los resultados anteriores
3. **Comparaci√≥n rigurosa:** Todas las configuraciones se eval√∫an en el mismo conjunto de test
4. **An√°lisis de resultados:** Hip√≥tesis sobre por qu√© ciertas t√©cnicas funcionan o no

### T√©cnicas Evaluadas

- ‚úÖ **EarlyStopping y ReduceLROnPlateau:** Mejora m√°s efectiva
- ‚úÖ **Bidirectional LSTM:** Mejor arquitectura individual
- ‚úÖ **Dropout final:** Mejora marginal pero √∫til
- ‚ö†Ô∏è **SpatialDropout1D:** Regulariz√≥ demasiado la entrada
- ‚ùå **Recurrent dropout:** Penaliz√≥ la memoria secuencial
- ‚ùå **L2 regularization:** Introdujo ruido en el aprendizaje
- ‚ùå **Stacked LSTM:** Requer√≠a m√°s datos para evitar sobreajuste
- ‚ö†Ô∏è **GloVe + Fine-tuning:** Estable pero no super√≥ el modelo puro

## üìù Notas

- Se recomienda usar GPU para entrenamiento m√°s r√°pido
- El modelo puede guardarse en formato `.keras` para reutilizaci√≥n
- Los embeddings GloVe deben descargarse previamente (glove.6B.100d.txt)
- Los modelos entrenados est√°n guardados en formato `.keras` (best_glove_frozen.keras, best_glove_tuned.keras, best_iter*.keras)
- El dataset IMDB se carga autom√°ticamente desde Keras

