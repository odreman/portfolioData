# Experimentaci√≥n con MLflow: Predicci√≥n de Tarifas de Taxi en NYC

## üìã Descripci√≥n

Este proyecto demuestra el uso pr√°ctico de MLflow para la experimentaci√≥n y gesti√≥n de modelos de machine learning. Se trabaja con un dataset real de viajes de taxi en Nueva York (NYC Taxi Trip Data) con m√°s de 1 mill√≥n de registros para predecir tarifas, utilizando MLflow para registrar experimentos, comparar modelos y gestionar el ciclo de vida de los modelos.

El objetivo principal no es solo obtener el mejor modelo, sino demostrar c√≥mo MLflow puede guiar el proceso de experimentaci√≥n y toma de decisiones en el desarrollo de modelos de machine learning.

## üéØ Objetivos

- Entrenar y comparar m√∫ltiples algoritmos de machine learning (regresi√≥n)
- Utilizar MLflow para registrar experimentos, m√©tricas, par√°metros y modelos
- Ajustar hiperpar√°metros bas√°ndose en los resultados registrados en MLflow
- Comparar el rendimiento de diferentes algoritmos para seleccionar el mejor modelo
- Documentar el proceso de experimentaci√≥n y los resultados obtenidos
- Demostrar c√≥mo MLflow facilita la reproducibilidad y comparaci√≥n sistem√°tica de modelos

## üìä Dataset

- **Dataset:** NYC Taxi Trip Data
- **Tama√±o:** M√°s de 1 mill√≥n de registros (muestra de 1M para experimentaci√≥n)
- **Variables principales:**
  - Fechas de pickup y dropoff
  - Coordenadas geogr√°ficas (pickup/dropoff)
  - Distancia del viaje
  - N√∫mero de pasajeros
  - Tarifa (variable objetivo)
- **Objetivo:** Predecir la tarifa del viaje (`fare_amount`)

## üõ†Ô∏è Herramientas Utilizadas

- **Python** para desarrollo y an√°lisis
- **Pandas** para manipulaci√≥n de datos
- **NumPy** para operaciones num√©ricas
- **Scikit-learn** para modelos de machine learning
- **XGBoost** para modelos de gradient boosting
- **MLflow** para tracking de experimentos y gesti√≥n de modelos
- **Matplotlib/Seaborn** para visualizaciones
- **Jupyter Notebook** para an√°lisis interactivo

## üìÇ Estructura del Proyecto

```
experimentacion_mlflow/
‚îú‚îÄ‚îÄ Taxi_Trip_Data.csv
‚îú‚îÄ‚îÄ experimentacion_mlflow.ipynb
‚îú‚îÄ‚îÄ experiment_report.md
‚îú‚îÄ‚îÄ [documentaci√≥n en PDF]
‚îú‚îÄ‚îÄ [archivos de visualizaciones y resultados]
‚îÇ   ‚îú‚îÄ‚îÄ eda_visualizations.png
‚îÇ   ‚îú‚îÄ‚îÄ model_comparison.png
‚îÇ   ‚îú‚îÄ‚îÄ feature_importance_*.png
‚îÇ   ‚îú‚îÄ‚îÄ correlation_matrix.csv
‚îÇ   ‚îî‚îÄ‚îÄ [otros artefactos]
‚îî‚îÄ‚îÄ README.md
```

## üîç Proceso de Experimentaci√≥n

### 1. Preparaci√≥n y Exploraci√≥n de Datos (EDA)

**Tracking con MLflow:**
- Registro de m√©tricas iniciales del dataset
- Tracking de transformaciones de datos
- Logging de visualizaciones EDA como artefactos
- An√°lisis de valores faltantes y tipos de datos

**Preprocesamiento realizado:**
- Limpieza de datos (valores negativos, outliers)
- Conversi√≥n de fechas y creaci√≥n de features temporales
- Feature engineering:
  - `hour`, `day_of_week`, `month`, `is_weekend`
  - `trip_duration` (duraci√≥n del viaje en minutos)
  - `avg_speed` (velocidad promedio)
- Manejo de valores at√≠picos (m√©todo de desviaci√≥n est√°ndar)
- Escalado de caracter√≠sticas (StandardScaler)

**Visualizaciones generadas:**
- Distribuci√≥n de tarifas
- Relaci√≥n distancia vs tarifa
- Tarifa promedio por hora y d√≠a de la semana
- Matriz de correlaci√≥n

### 2. Modelos Implementados

#### a. Modelo Base: Regresi√≥n Lineal
- **Prop√≥sito:** Baseline para comparaciones
- **M√©tricas registradas:** RMSE, MAE, R¬≤, varianza explicada
- **Caracter√≠sticas:** Coeficientes e intercept registrados
- **Visualizaciones:** Importancia de caracter√≠sticas basada en coeficientes

#### b. Random Forest con GridSearchCV
- **B√∫squeda de hiperpar√°metros:**
  - `n_estimators`: [100, 200]
  - `max_depth`: [10, 20]
  - `min_samples_split`: [2, 5]
  - `min_samples_leaf`: [1, 2]
- **Tracking:** Resultados de cross-validation (3 folds)
- **Artefactos:** Feature importance, resultados de CV
- **M√©tricas:** RMSE, R¬≤, MAE en train y test

#### c. XGBoost con GridSearchCV
- **B√∫squeda de hiperpar√°metros:**
  - `max_depth`: [3, 5]
  - `learning_rate`: [0.01, 0.1]
  - `n_estimators`: [100, 200]
  - `min_child_weight`: [1, 3]
  - `subsample`: [0.8, 1.0]
  - `colsample_bytree`: [0.8, 1.0]
- **Caracter√≠sticas avanzadas:**
  - Early stopping
  - Learning curves
  - M√∫ltiples m√©tricas de evaluaci√≥n
- **Tracking:** Resultados detallados de CV, curvas de aprendizaje

#### d. Modelo Refinado
- **Mejoras:** Features polin√≥micas, validaci√≥n cruzada extendida
- **An√°lisis:** An√°lisis de residuos detallado
- **Optimizaci√≥n:** Ajuste fino basado en resultados anteriores

### 3. Uso de MLflow para Guiar Decisiones

#### Tracking de Experimentos
- **M√©tricas:** RMSE, MAE, R¬≤, varianza explicada, error relativo
- **Par√°metros:** Configuraciones de modelos, transformaciones, hiperpar√°metros
- **Artefactos:** Gr√°ficos, resultados de CV, modelos serializados, visualizaciones

#### Comparaci√≥n de Modelos
- B√∫squeda sistem√°tica de runs en MLflow
- Ordenamiento por m√©tricas (RMSE ascendente)
- An√°lisis comparativo de rendimiento
- Identificaci√≥n del mejor modelo

#### An√°lisis de Resultados
- Visualizaciones comparativas
- An√°lisis de trade-offs (precisi√≥n vs tiempo de ejecuci√≥n)
- Evaluaci√≥n de overfitting (diferencia train-test)
- An√°lisis de importancia de features

### 4. Decisiones Guiadas por MLflow

#### Selecci√≥n de Features
- Tracking de importancia de caracter√≠sticas
- An√°lisis del impacto en m√©tricas
- Identificaci√≥n de features m√°s relevantes

#### Optimizaci√≥n de Hiperpar√°metros
- Comparaci√≥n de diferentes configuraciones
- An√°lisis de tendencias en m√©tricas
- Selecci√≥n basada en resultados de CV

#### Manejo de Overfitting
- Monitoreo de diferencias train-test
- Ajuste de complejidad del modelo
- Validaci√≥n cruzada para evaluaci√≥n robusta

## üìä Resultados

### Mejor Modelo: XGBoost Detallado

**M√©tricas finales:**
- **RMSE:** 0.7433
- **R¬≤:** 0.9836
- **MAE:** 0.2763
- **Mejora sobre baseline:** 11.12%
- **Tiempo de ejecuci√≥n:** 289.91 segundos

### Comparaci√≥n de Modelos

| Modelo | Test RMSE | Test R¬≤ | Test MAE | Train-Test Diff | Tiempo (s) |
|--------|-----------|---------|----------|-----------------|------------|
| XGBoost Detallado | 0.7433 | 0.9836 | 0.2763 | 0.0044 | 289.91 |
| Random Forest Detallado | 0.7434 | 0.9836 | 0.2699 | 0.0338 | 1023.92 |
| Modelo Refinado | 0.7525 | 0.9832 | 0.2680 | 0.0545 | 810.26 |
| Linear Regression | 0.8363 | 0.9792 | 0.3404 | 0.0456 | 2.57 |

### Hiperpar√°metros √ìptimos (XGBoost)

- `max_depth`: 5
- `learning_rate`: 0.1
- `n_estimators`: 100
- `min_child_weight`: 3
- `subsample`: 1.0
- `colsample_bytree`: 0.8

## üìù Temas Cubiertos

- Experimentaci√≥n sistem√°tica con MLflow
- Tracking de experimentos de machine learning
- Gesti√≥n del ciclo de vida de modelos (MLOps)
- Comparaci√≥n de algoritmos de regresi√≥n
- Optimizaci√≥n de hiperpar√°metros con GridSearchCV
- Feature engineering y selecci√≥n
- An√°lisis de importancia de features
- Visualizaci√≥n de resultados de modelos
- An√°lisis de residuos y overfitting
- Reproducibilidad en machine learning

## üöÄ Ejecuci√≥n

### Requisitos Previos
- MLflow server ejecut√°ndose en `http://localhost:5001`
- Python 3.x con las dependencias instaladas
- Dataset `Taxi_Trip_Data.csv` en el directorio del proyecto

### Instalaci√≥n de Dependencias

Se recomienda crear un entorno virtual para este proyecto.

```bash
# Crear entorno virtual (opcional)
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalaci√≥n de librer√≠as principales
pip install pandas numpy scikit-learn xgboost mlflow matplotlib seaborn tabulate
```

> [!NOTE]
> Las versiones espec√≠ficas utilizadas en el desarrollo son:
> - pandas>=1.2
> - numpy>=1.20
> - scikit-learn
> - xgboost
> - mlflow
> - matplotlib>=3.4
> - seaborn>=0.11

### Iniciar MLflow Server

```bash
mlflow ui --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --port 5001
```

### Ejecutar el An√°lisis

```bash
cd experimentacion_mlflow
jupyter notebook experimentacion_mlflow.ipynb
```

### Acceder a MLflow UI

Una vez ejecutado el notebook, puedes ver todos los experimentos en:
```
http://localhost:5001
```

## üìÑ Resultados y Artefactos

El proyecto incluye:
- **experiment_report.md**: Reporte detallado de los experimentos con comparaci√≥n de modelos
- **Documentaci√≥n en PDF**: Documentaci√≥n completa del proceso, metodolog√≠a y resultados
- **Visualizaciones:**
  - Comparaci√≥n de modelos
  - Importancia de features por modelo
  - An√°lisis de residuos
  - Curvas de aprendizaje (XGBoost)
- **Resultados de CV:** Archivos CSV con resultados detallados de cross-validation
- **Matrices de correlaci√≥n:** An√°lisis de relaciones entre variables

## üí° Lecciones Aprendidas

1. **MLflow facilit√≥ la comparaci√≥n sistem√°tica de modelos** - La capacidad de comparar m√∫ltiples experimentos de forma visual y estructurada fue fundamental para la toma de decisiones.

2. **El tracking autom√°tico permiti√≥ identificar patrones de mejora** - Al registrar todos los par√°metros y m√©tricas, fue posible identificar qu√© configuraciones funcionaban mejor.

3. **La gesti√≥n de artefactos ayud√≥ en el an√°lisis visual** - Tener todas las visualizaciones y resultados centralizados facilit√≥ el an√°lisis y la documentaci√≥n.

4. **Reproducibilidad mejorada** - El versionado autom√°tico de modelos y par√°metros permite reproducir cualquier experimento en el futuro.

## üîó Siguiente Paso

Una vez seleccionado el mejor modelo (XGBoost), este se registra en MLflow Model Registry y se despliega como servicio web en el proyecto [Despliegue de Modelo como Servicio Web](./../despliegue_modelo_servicio_web/).

## üìÑ Licencia

Este portafolio es de car√°cter educativo y personal.

---

**√öltima actualizaci√≥n:** 2024
