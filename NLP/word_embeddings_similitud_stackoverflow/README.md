# Word Embeddings para Encontrar Preguntas Similares en StackOverflow

## ğŸ“‹ DescripciÃ³n

Este proyecto resuelve el problema de encontrar preguntas duplicadas o similares en un foro, aplicado especÃ­ficamente a los tÃ­tulos de preguntas en StackOverflow. La estrategia se basa en encontrar textos que son similares semÃ¡nticamente utilizando word embeddings.

## ğŸ¯ Objetivo

Implementar un sistema de bÃºsqueda de preguntas similares en StackOverflow que:
- Cuando un usuario escribe el tÃ­tulo de una nueva pregunta, muestre un conjunto de preguntas similares
- Permita verificar si ya existe una pregunta duplicada
- Utilice word embeddings para medir similitud semÃ¡ntica
- EvalÃºe la eficacia del sistema utilizando mÃ©tricas de ranking

## ğŸ“Š Dataset

- **Fuente:** TÃ­tulos de preguntas de StackOverflow
- **Estructura:** Dataset con preguntas y sus duplicados identificados
- **Idioma:** InglÃ©s
- **Uso:** Identificar preguntas similares o duplicadas

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Gensim** - Word embeddings (Word2Vec)
- **SentenceTransformers** - Sentence embeddings
- **NumPy** - ComputaciÃ³n numÃ©rica
- **Scikit-learn** - Herramientas de machine learning y evaluaciÃ³n
- **NLTK** - Procesamiento de texto

## ğŸ“– Temas Cubiertos

- Word embeddings (Word2Vec de Google News)
- Sentence embeddings
- Similitud semÃ¡ntica entre textos
- Problemas de ranking e information retrieval
- MÃ©tricas: Hits@K, DCG@K
- Preprocesamiento de texto para embeddings
- ConversiÃ³n de texto a embeddings (Question2Vec)
- Entrenamiento de embeddings personalizados con Gensim
- ComparaciÃ³n de diferentes enfoques de embeddings

## ğŸ“ Estructura del Proyecto

```
word_embeddings_similitud_stackoverflow/
â”œâ”€â”€ README.md
â””â”€â”€ 03_word_embeddings_challenge/
    â”œâ”€â”€ word_embeddings_similitud_stackoverflow.ipynb
    â”œâ”€â”€ s03_utils.py
    â”œâ”€â”€ custom_word2vec.model
    â”œâ”€â”€ data/
    â””â”€â”€ resources/
        â”œâ”€â”€ 1607.01759.pdf
        â”œâ”€â”€ CBOW.png
        â”œâ”€â”€ Skip-gram.png
        â””â”€â”€ sparse_vs_dense.png
```

## ğŸš€ EjecuciÃ³n

1. AsegÃºrate de tener instaladas las dependencias:
```bash
pip install gensim sentence-transformers numpy scikit-learn nltk
```

2. **Descarga de embeddings**: El proyecto utiliza Word2Vec pre-entrenado de Google News. Se descargarÃ¡ automÃ¡ticamente la primera vez que se ejecute, o puedes descargarlo manualmente.

3. **GPU recomendada**: Para la segunda parte del anÃ¡lisis (sentence transformers), se recomienda el uso de GPU para mejor rendimiento.

4. Abre el notebook `word_embeddings_similitud_stackoverflow.ipynb` en Jupyter

5. Ejecuta todas las celdas para ver el anÃ¡lisis completo

## ğŸ“ˆ Resultados Clave

- Sistema de bÃºsqueda de preguntas similares funcional
- ComparaciÃ³n de diferentes enfoques de embeddings
- EvaluaciÃ³n con mÃ©tricas de ranking (Hits@K, DCG@K)
- AnÃ¡lisis de la efectividad de word embeddings vs sentence embeddings
- Entrenamiento de embeddings personalizados

## ğŸ’¡ CaracterÃ­sticas Especiales

- **MÃºltiples enfoques**: Compara Word2Vec, SentenceTransformers y embeddings personalizados
- **MÃ©tricas de ranking**: Utiliza Hits@K y DCG@K para evaluar el sistema
- **Preprocesamiento**: Incluye tÃ©cnicas de preprocesamiento especÃ­ficas para embeddings
- **Extras**: Incluye secciones adicionales sobre FastText, efecto del preprocesado en Transformers, y entrenamiento de embeddings personalizados

## ğŸ” MÃ©tricas Utilizadas

- **Hits@K**: Porcentaje de casos donde la pregunta correcta estÃ¡ en el top K resultados
- **DCG@K**: Discounted Cumulative Gain, mide la calidad del ranking considerando la posiciÃ³n

## ğŸ”— Enlaces

- [Notebook completo](03_word_embeddings_challenge/word_embeddings_similitud_stackoverflow.ipynb)
- [Volver al Ã­ndice de NLP](../README.md)

