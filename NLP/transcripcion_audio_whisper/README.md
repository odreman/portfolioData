# TranscripciÃ³n de Audio con Whisper y ClasificaciÃ³n Zero-Shot

## ğŸ“‹ DescripciÃ³n

Este proyecto demuestra cÃ³mo construir aplicaciones web con modelos Transformer para procesamiento del lenguaje natural, especÃ­ficamente para transcripciÃ³n de audio y clasificaciÃ³n de texto zero-shot.

## ğŸ¯ Objetivo

Construir aplicaciones web interactivas utilizando modelos Transformer para:
1. TranscripciÃ³n de audio multilingÃ¼e con Whisper
2. ClasificaciÃ³n de texto zero-shot sin necesidad de entrenamiento previo
3. CombinaciÃ³n de ambas tÃ©cnicas en un clasificador de audios zero-shot

## ğŸ“Š Contenido del Proyecto

El proyecto incluye:
- **Ejemplo I**: Interfaz de usuario para transcripciÃ³n de audio con Gradio
- **Ejemplo II**: ClasificaciÃ³n de texto zero-shot con modelos Transformer
- **Demo completa**: Clasificador de audios zero-shot que combina transcripciÃ³n y clasificaciÃ³n

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Transformers (Hugging Face)** - Modelos pre-entrenados de NLP
- **Gradio** - ConstrucciÃ³n de interfaces web interactivas
- **Faster-Whisper** - TranscripciÃ³n de audio multilingÃ¼e optimizada
- **PyTorch** - Framework de deep learning
- **OpenAI Whisper** - Modelo de transcripciÃ³n de audio

## ğŸ“– Temas Cubiertos

- TranscripciÃ³n de audio con Whisper
- ClasificaciÃ³n zero-shot con modelos Transformer (BART, DeBERTa)
- ConstrucciÃ³n de interfaces web con Gradio
- Pipeline de procesamiento de audio y texto
- Aplicaciones interactivas de NLP
- Prompt engineering para clasificaciÃ³n zero-shot

## ğŸ“ Estructura del Proyecto

```
transcripcion_audio_whisper/
â”œâ”€â”€ README.md
â””â”€â”€ transcripcion_audio_whisper.ipynb
```

## ğŸš€ EjecuciÃ³n

1. AsegÃºrate de tener instaladas las dependencias:
```bash
pip install transformers gradio faster-whisper sentencepiece torch
```

2. **Importante**: Para que las demostraciones se ejecuten rÃ¡pidamente, se recomienda usar una GPU. Activa la GPU en tu entorno (Colab, Jupyter, etc.) antes de ejecutar las celdas.

3. Abre el notebook `transcripcion_audio_whisper.ipynb` en Jupyter

4. Ejecuta todas las celdas para ver las demostraciones completas

## ğŸ“ˆ Resultados Clave

- Interfaz interactiva para transcripciÃ³n de audio multilingÃ¼e
- Sistema de clasificaciÃ³n zero-shot que funciona con mÃºltiples idiomas
- Demo completa de clasificador de audios que combina transcripciÃ³n y clasificaciÃ³n
- AplicaciÃ³n prÃ¡ctica de modelos Transformer en problemas reales

## ğŸ’¡ CaracterÃ­sticas Especiales

- **MultilingÃ¼e**: Los modelos funcionan con mÃºltiples idiomas (inglÃ©s, espaÃ±ol, etc.)
- **Zero-shot**: No requiere entrenamiento previo para nuevas tareas de clasificaciÃ³n
- **Interactivo**: Interfaces web construidas con Gradio para fÃ¡cil uso
- **Optimizado**: Uso de Faster-Whisper para transcripciÃ³n eficiente

## ğŸ”— Enlaces

- [Notebook completo](../transcripcion_audio_whisper.ipynb)
- [Volver al Ã­ndice de NLP](../README.md)

